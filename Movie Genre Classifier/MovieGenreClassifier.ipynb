{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae5a1e2-ef3a-4ddc-84b5-e532bcf09801",
   "metadata": {},
   "source": [
    "# Task: MOVIE GENRE CLASSIFICATION\n",
    "    Create a machine learning model that can predict the genre of a\n",
    "    movie based on its plot summary or other textual information. You\n",
    "    can use techniques like TF-IDF or word embeddings with classifiers\n",
    "    such as Naive Bayes, Logistic Regression, or Support Vector\n",
    "    Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2595aac1-0b79-4c61-baf1-5eefcc0b947a",
   "metadata": {},
   "source": [
    "## Methodologies\n",
    "\n",
    "###    1. Data Collection\n",
    "###    2. Data Cleaning and Preprocessing\n",
    "###    3. Data Visualization\n",
    "###    4. Feature Engineering\n",
    "###    5. Model Selection\n",
    "###    6. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b90354-d58d-4edd-9bf7-d9db2c694008",
   "metadata": {},
   "source": [
    "## Data Collection: Data was collected from https://www.kaggle.com/code/dhruvtibarewal/movie-genre-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62062b37-acef-4b98-948c-343c87d5a4f7",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f960f8-7709-4acd-b591-5f9183a4444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0f39ea-dcea-4949-b2cb-bdbb0566d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:/Users/susha/Downloads/archive (7)/Genre Classification Dataset/train_data.txt\", delimiter=':::', names = ['Sno', 'Name', 'Genre', 'Description'] ,engine='python')\n",
    "test_data = pd.read_csv(\"C:/Users/susha/Downloads/archive (7)/Genre Classification Dataset/test_data.txt\", delimiter = ':::', names = ['Sno', 'Name', 'Description'], engine='python')\n",
    "test_data_solution = pd.read_csv(\"C:/Users/susha/Downloads/archive (7)/Genre Classification Dataset/test_data_solution.txt\", delimiter=':::', names = ['Sno', 'Name', 'Genre', 'Description'] ,engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0a6135-297d-4720-9ee1-a346d43af644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54195</th>\n",
       "      <td>54196</td>\n",
       "      <td>\"Tales of Light &amp; Dark\" (2013)</td>\n",
       "      <td>horror</td>\n",
       "      <td>Covering multiple genres, Tales of Light &amp; Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54196</th>\n",
       "      <td>54197</td>\n",
       "      <td>Der letzte Mohikaner (1965)</td>\n",
       "      <td>western</td>\n",
       "      <td>As Alice and Cora Munro attempt to find their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54197</th>\n",
       "      <td>54198</td>\n",
       "      <td>Oliver Twink (2007)</td>\n",
       "      <td>adult</td>\n",
       "      <td>A movie 169 years in the making. Oliver Twist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54198</th>\n",
       "      <td>54199</td>\n",
       "      <td>Slipstream (1973)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Popular, but mysterious rock D.J Mike Mallard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54199</th>\n",
       "      <td>54200</td>\n",
       "      <td>Curitiba Zero Grau (2010)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Curitiba is a city in movement, with rhythms ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sno                              Name      Genre  \\\n",
       "54195  54196   \"Tales of Light & Dark\" (2013)     horror    \n",
       "54196  54197      Der letzte Mohikaner (1965)    western    \n",
       "54197  54198              Oliver Twink (2007)      adult    \n",
       "54198  54199                Slipstream (1973)      drama    \n",
       "54199  54200        Curitiba Zero Grau (2010)      drama    \n",
       "\n",
       "                                             Description  \n",
       "54195   Covering multiple genres, Tales of Light & Da...  \n",
       "54196   As Alice and Cora Munro attempt to find their...  \n",
       "54197   A movie 169 years in the making. Oliver Twist...  \n",
       "54198   Popular, but mysterious rock D.J Mike Mallard...  \n",
       "54199   Curitiba is a city in movement, with rhythms ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()\n",
    "test_data.head()\n",
    "test_data_solution.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1916cef-9d81-4ae2-bb3a-830d35488e35",
   "metadata": {},
   "source": [
    "#### Looking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6fa0ec-cee8-40f4-ae18-0528e7ee7ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54214 entries, 0 to 54213\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Sno          54214 non-null  int64 \n",
      " 1   Name         54214 non-null  object\n",
      " 2   Genre        54214 non-null  object\n",
      " 3   Description  54214 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.7+ MB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54200 entries, 0 to 54199\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Sno          54200 non-null  int64 \n",
      " 1   Name         54200 non-null  object\n",
      " 2   Description  54200 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54200 entries, 0 to 54199\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Sno          54200 non-null  int64 \n",
      " 1   Name         54200 non-null  object\n",
      " 2   Genre        54200 non-null  object\n",
      " 3   Description  54200 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#looking for null values\n",
    "\n",
    "train_data.info()\n",
    "print('\\n')\n",
    "test_data.info()\n",
    "print('\\n')\n",
    "test_data_solution.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3003746d-cc22-4e29-b1f3-6a682f34e941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sno            0\n",
       "Name           0\n",
       "Genre          0\n",
       "Description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()\n",
    "\n",
    "test_data.isna().sum()\n",
    "\n",
    "test_data_solution.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab90ca7-0ff2-4d7f-a19f-98f00a92da96",
   "metadata": {},
   "source": [
    "#### Looking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00534954-04c3-4232-ac17-bddda3abda28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.duplicated().sum()\n",
    "test_data.duplicated().sum()\n",
    "test_data_solution.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979b13b-1d5f-43a8-8304-44fd949d9f5b",
   "metadata": {},
   "source": [
    "#### Data Cleaning is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29af0f8-e6ca-4f95-8289-0a73249ccbd0",
   "metadata": {},
   "source": [
    "## Futher preprocessing\n",
    "#### The dataset here is almost 50% training  and 50% testing. \n",
    "#### This is far from the optimal ratio that will yield in a better working model. \n",
    "#### So we will be splitting the dataset in the format 70-15-15 for training, validation and testing respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc55877-ca4e-4416-b98a-60ff119a90be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bfa24e3-f715-41d8-b156-3e3b211d83a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54214\n",
      "         Sno                                    Name          Genre  \\\n",
      "0      54216                   Edgar's Lunch (1998)       thriller    \n",
      "1      54217               La guerra de papá (1977)         comedy    \n",
      "2      54218            Off the Beaten Track (2010)    documentary    \n",
      "3      54219                 Meu Amigo Hindu (2015)          drama    \n",
      "4      54220                      Er nu zhai (1955)          drama    \n",
      "...      ...                                     ...            ...   \n",
      "37695  91911                    Fully Loaded (2011)         comedy    \n",
      "37696  91912                    Tenebrae Lux (2014)         sci-fi    \n",
      "37697  91913                   Mexican Dance (1898)          short    \n",
      "37698  91914   Das Lied von den zwei Pferden (2009)    documentary    \n",
      "37699  91915                  Doin' It Again (2012)    documentary    \n",
      "\n",
      "                                             Description  \n",
      "0       L.R. Brane loves his life - his car, his apar...  \n",
      "1       Spain, March 1964: Quico is a very naughty ch...  \n",
      "2       One year in the life of Albin and his family ...  \n",
      "3       His father has died, he hasn't spoken with hi...  \n",
      "4       Before he was known internationally as a mart...  \n",
      "...                                                  ...  \n",
      "37695   On a rare evening out, two feisty single moms...  \n",
      "37696   A lone traveler with the ability to cross bet...  \n",
      "37697   \"Another well-known dancer with a national re...  \n",
      "37698   A promise, an old, destroyed horse head violi...  \n",
      "37699   50th Anniversary - 1st album of new material ...  \n",
      "\n",
      "[37700 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\susha\\AppData\\Local\\Temp\\ipykernel_10696\\1078671139.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(rows_to_append)\n"
     ]
    }
   ],
   "source": [
    "#code below adds the first 37700 data from test_data_solution into the train datasets and removes those respective data from itself and test_data\n",
    "\n",
    "last_sno = train_data['Sno'].max()\n",
    "print(last_sno)\n",
    "\n",
    "rows_to_append = test_data_solution.head(37700).copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "rows_to_append.loc[:, 'Sno'] += last_sno + 1  # Use .loc to modify the DataFrame safely\n",
    "\n",
    "print(rows_to_append)\n",
    "\n",
    "\n",
    "train_data = train_data.append(rows_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ae1fa90-097e-4b7f-80b4-adf6b9452450",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(rows_to_append.index)\n",
    "test_data_solution = test_data_solution.drop(rows_to_append.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5018a4f5-8067-421d-b0c1-7de13c6d889b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oscar et la dame rose (2009)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cupid (1997)</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Young, Wild and Wonderful (1980)</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Secret Sin (1915)</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Unrecovered (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>The film's title refers not only to the un-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37695</th>\n",
       "      <td>91911</td>\n",
       "      <td>Fully Loaded (2011)</td>\n",
       "      <td>comedy</td>\n",
       "      <td>On a rare evening out, two feisty single moms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37696</th>\n",
       "      <td>91912</td>\n",
       "      <td>Tenebrae Lux (2014)</td>\n",
       "      <td>sci-fi</td>\n",
       "      <td>A lone traveler with the ability to cross bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37697</th>\n",
       "      <td>91913</td>\n",
       "      <td>Mexican Dance (1898)</td>\n",
       "      <td>short</td>\n",
       "      <td>\"Another well-known dancer with a national re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37698</th>\n",
       "      <td>91914</td>\n",
       "      <td>Das Lied von den zwei Pferden (2009)</td>\n",
       "      <td>documentary</td>\n",
       "      <td>A promise, an old, destroyed horse head violi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37699</th>\n",
       "      <td>91915</td>\n",
       "      <td>Doin' It Again (2012)</td>\n",
       "      <td>documentary</td>\n",
       "      <td>50th Anniversary - 1st album of new material ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91914 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sno                                    Name          Genre  \\\n",
       "0          1           Oscar et la dame rose (2009)          drama    \n",
       "1          2                           Cupid (1997)       thriller    \n",
       "2          3       Young, Wild and Wonderful (1980)          adult    \n",
       "3          4                  The Secret Sin (1915)          drama    \n",
       "4          5                 The Unrecovered (2007)          drama    \n",
       "...      ...                                     ...            ...   \n",
       "37695  91911                    Fully Loaded (2011)         comedy    \n",
       "37696  91912                    Tenebrae Lux (2014)         sci-fi    \n",
       "37697  91913                   Mexican Dance (1898)          short    \n",
       "37698  91914   Das Lied von den zwei Pferden (2009)    documentary    \n",
       "37699  91915                  Doin' It Again (2012)    documentary    \n",
       "\n",
       "                                             Description  \n",
       "0       Listening in to a conversation between his do...  \n",
       "1       A brother and sister with a past incestuous r...  \n",
       "2       As the bus empties the students for their fie...  \n",
       "3       To help their unemployed father make ends mee...  \n",
       "4       The film's title refers not only to the un-re...  \n",
       "...                                                  ...  \n",
       "37695   On a rare evening out, two feisty single moms...  \n",
       "37696   A lone traveler with the ability to cross bet...  \n",
       "37697   \"Another well-known dancer with a national re...  \n",
       "37698   A promise, an old, destroyed horse head violi...  \n",
       "37699   50th Anniversary - 1st album of new material ...  \n",
       "\n",
       "[91914 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cff59315-b916-40ad-8c6d-5857ab662ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37700</th>\n",
       "      <td>37701</td>\n",
       "      <td>My Lips Betray (1933)</td>\n",
       "      <td>In a make-believe, mittleuropean kingdom, a v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37701</th>\n",
       "      <td>37702</td>\n",
       "      <td>The Koreas (2016)</td>\n",
       "      <td>At the end of World War II, Korea was divided...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37702</th>\n",
       "      <td>37703</td>\n",
       "      <td>Come Together (2016)</td>\n",
       "      <td>Colombia is coming out of a period in their h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37703</th>\n",
       "      <td>37704</td>\n",
       "      <td>With Honors Denied (2003)</td>\n",
       "      <td>Japanese bombs hit Pearl Harbor on a Sunday. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37704</th>\n",
       "      <td>37705</td>\n",
       "      <td>\"Connect with English\" (2007)</td>\n",
       "      <td>Connect with English is a series that brings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54195</th>\n",
       "      <td>54196</td>\n",
       "      <td>\"Tales of Light &amp; Dark\" (2013)</td>\n",
       "      <td>Covering multiple genres, Tales of Light &amp; Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54196</th>\n",
       "      <td>54197</td>\n",
       "      <td>Der letzte Mohikaner (1965)</td>\n",
       "      <td>As Alice and Cora Munro attempt to find their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54197</th>\n",
       "      <td>54198</td>\n",
       "      <td>Oliver Twink (2007)</td>\n",
       "      <td>A movie 169 years in the making. Oliver Twist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54198</th>\n",
       "      <td>54199</td>\n",
       "      <td>Slipstream (1973)</td>\n",
       "      <td>Popular, but mysterious rock D.J Mike Mallard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54199</th>\n",
       "      <td>54200</td>\n",
       "      <td>Curitiba Zero Grau (2010)</td>\n",
       "      <td>Curitiba is a city in movement, with rhythms ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sno                              Name  \\\n",
       "37700  37701            My Lips Betray (1933)    \n",
       "37701  37702                The Koreas (2016)    \n",
       "37702  37703             Come Together (2016)    \n",
       "37703  37704        With Honors Denied (2003)    \n",
       "37704  37705    \"Connect with English\" (2007)    \n",
       "...      ...                               ...   \n",
       "54195  54196   \"Tales of Light & Dark\" (2013)    \n",
       "54196  54197      Der letzte Mohikaner (1965)    \n",
       "54197  54198              Oliver Twink (2007)    \n",
       "54198  54199                Slipstream (1973)    \n",
       "54199  54200        Curitiba Zero Grau (2010)    \n",
       "\n",
       "                                             Description  \n",
       "37700   In a make-believe, mittleuropean kingdom, a v...  \n",
       "37701   At the end of World War II, Korea was divided...  \n",
       "37702   Colombia is coming out of a period in their h...  \n",
       "37703   Japanese bombs hit Pearl Harbor on a Sunday. ...  \n",
       "37704   Connect with English is a series that brings ...  \n",
       "...                                                  ...  \n",
       "54195   Covering multiple genres, Tales of Light & Da...  \n",
       "54196   As Alice and Cora Munro attempt to find their...  \n",
       "54197   A movie 169 years in the making. Oliver Twist...  \n",
       "54198   Popular, but mysterious rock D.J Mike Mallard...  \n",
       "54199   Curitiba is a city in movement, with rhythms ...  \n",
       "\n",
       "[16500 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9adf68f7-9fea-444a-93c9-5ee68c03c4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37700</th>\n",
       "      <td>37701</td>\n",
       "      <td>My Lips Betray (1933)</td>\n",
       "      <td>musical</td>\n",
       "      <td>In a make-believe, mittleuropean kingdom, a v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37701</th>\n",
       "      <td>37702</td>\n",
       "      <td>The Koreas (2016)</td>\n",
       "      <td>documentary</td>\n",
       "      <td>At the end of World War II, Korea was divided...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37702</th>\n",
       "      <td>37703</td>\n",
       "      <td>Come Together (2016)</td>\n",
       "      <td>documentary</td>\n",
       "      <td>Colombia is coming out of a period in their h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37703</th>\n",
       "      <td>37704</td>\n",
       "      <td>With Honors Denied (2003)</td>\n",
       "      <td>short</td>\n",
       "      <td>Japanese bombs hit Pearl Harbor on a Sunday. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37704</th>\n",
       "      <td>37705</td>\n",
       "      <td>\"Connect with English\" (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Connect with English is a series that brings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54195</th>\n",
       "      <td>54196</td>\n",
       "      <td>\"Tales of Light &amp; Dark\" (2013)</td>\n",
       "      <td>horror</td>\n",
       "      <td>Covering multiple genres, Tales of Light &amp; Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54196</th>\n",
       "      <td>54197</td>\n",
       "      <td>Der letzte Mohikaner (1965)</td>\n",
       "      <td>western</td>\n",
       "      <td>As Alice and Cora Munro attempt to find their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54197</th>\n",
       "      <td>54198</td>\n",
       "      <td>Oliver Twink (2007)</td>\n",
       "      <td>adult</td>\n",
       "      <td>A movie 169 years in the making. Oliver Twist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54198</th>\n",
       "      <td>54199</td>\n",
       "      <td>Slipstream (1973)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Popular, but mysterious rock D.J Mike Mallard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54199</th>\n",
       "      <td>54200</td>\n",
       "      <td>Curitiba Zero Grau (2010)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Curitiba is a city in movement, with rhythms ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sno                              Name          Genre  \\\n",
       "37700  37701            My Lips Betray (1933)        musical    \n",
       "37701  37702                The Koreas (2016)    documentary    \n",
       "37702  37703             Come Together (2016)    documentary    \n",
       "37703  37704        With Honors Denied (2003)          short    \n",
       "37704  37705    \"Connect with English\" (2007)          drama    \n",
       "...      ...                               ...            ...   \n",
       "54195  54196   \"Tales of Light & Dark\" (2013)         horror    \n",
       "54196  54197      Der letzte Mohikaner (1965)        western    \n",
       "54197  54198              Oliver Twink (2007)          adult    \n",
       "54198  54199                Slipstream (1973)          drama    \n",
       "54199  54200        Curitiba Zero Grau (2010)          drama    \n",
       "\n",
       "                                             Description  \n",
       "37700   In a make-believe, mittleuropean kingdom, a v...  \n",
       "37701   At the end of World War II, Korea was divided...  \n",
       "37702   Colombia is coming out of a period in their h...  \n",
       "37703   Japanese bombs hit Pearl Harbor on a Sunday. ...  \n",
       "37704   Connect with English is a series that brings ...  \n",
       "...                                                  ...  \n",
       "54195   Covering multiple genres, Tales of Light & Da...  \n",
       "54196   As Alice and Cora Munro attempt to find their...  \n",
       "54197   A movie 169 years in the making. Oliver Twist...  \n",
       "54198   Popular, but mysterious rock D.J Mike Mallard...  \n",
       "54199   Curitiba is a city in movement, with rhythms ...  \n",
       "\n",
       "[16500 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "876057c3-28a6-4c16-a64e-d9adcc056ad1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1541890828.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\susha\\AppData\\Local\\Temp\\ipykernel_10696\\1541890828.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    train_data.\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04f958c0-0ca0-4f14-90db-18040dd0acd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sno                                                        54202\n",
       "Name                                        Singing Guns (1950) \n",
       "Genre                                                   western \n",
       "Description     Rhiannon, an outlaw who regularly robs gold f...\n",
       "Name: 54201, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[54201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e37779-cf62-4918-b05c-09617372e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_solution.reset_index(drop=True, inplace=True)\n",
    "test_data_solution.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8e5f03c-66a3-44f2-aa61-7d7afca3c552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sno', 'Name', 'Genre', 'Description'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_solution.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4742ec32-7511-43c4-aabf-20f59eea41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.reset_index(drop=True, inplace=True)\n",
    "test_data.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e8ac2c0-ad1a-4e77-b8dd-37251e264609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "634b3280-12df-47a2-ab17-34c42a8efab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\susha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\susha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2bb886d-3c57-481d-abf6-eb6e6bd1215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    # Remove special characters, punctuation, and symbols\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    preprocessed_text = ' '.join(stemmed_tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "\n",
    "# Apply preprocessing to 'Description' column\n",
    "train_data['Description'] = train_data['Description'].apply(preprocess_text)\n",
    "test_data['Description'] = test_data['Description'].apply(preprocess_text)\n",
    "test_data_solution['Description'] = test_data_solution['Description'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7585bb6-caf2-4246-8ad4-644bcba12d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data['Description']\n",
    "y_train = train_data['Genre']\n",
    "X_test = test_data['Description']\n",
    "y_test_solution = test_data_solution['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e926400-2cf7-4905-b0c7-2cc975aa8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_solution_encoded = label_encoder.transform(y_test_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa72b13-f7ab-46ce-8c40-d7ebf50a777d",
   "metadata": {},
   "source": [
    "### Using TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6338a105-f42e-4b27-8736-77d8dc2a18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=100)  \n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7d521e4-a18a-46bd-a9a8-80563382c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42587878787878786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\susha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_solution_encoded, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "336c69f7-725c-4a8d-9973-17fba9762430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1479"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = train_data['Description'].apply(lambda x: len(word_tokenize(x))).max()\n",
    "max_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a35f8-0fe0-4639-adb1-8b62d457c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a4c15a9c-f6e9-4bdc-95c0-f8d68466bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000) \n",
    "\n",
    "# Fit and transform the training and test text data\n",
    "X_train_vectorized = vectorizer.fit_transform(train_data['Description'])\n",
    "X_test_vectorized = vectorizer.transform(test_data['Description'])\n",
    "\n",
    "# Convert sparse matrices to dense arrays\n",
    "X_train_dense = X_train_vectorized.toarray()\n",
    "X_test_dense = X_test_vectorized.toarray()\n",
    "\n",
    "# Define maximum sequence length based on the maximum number of tokens\n",
    "max_length = 800  \n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X_train_padded = pad_sequences(X_train_dense, maxlen=max_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_dense, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "71bf9832-a81a-4f35-8bca-01f34116cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(vectorizer.vocabulary_), output_dim=100, input_length=max_length),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(len(np.unique(y_train_encoded)), activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e429e6a2-c454-46ef-bf63-687a96141ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f6dbfb-adf7-4083-aabb-98be5260685f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2586/2586 [==============================] - ETA: 0s - loss: 2.3523 - accuracy: 0.2456"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_padded, y_train_encoded, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43068633-0281-4293-8119-bd716f979926",
   "metadata": {},
   "source": [
    "### Using Word2Vec vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdf13dd3-8ccd-440f-b16c-b422fbfa8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97235332-b74a-42e5-8bb4-1e51a4880817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=train_data['Description'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to calculate document vectors\n",
    "def calculate_doc_vector(tokens):\n",
    "    vectors = [word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(word2vec_model.vector_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9212bc27-3b01-4b16-9c8f-30c453344a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate document vectors for train and test data\n",
    "X_train_vectors = np.array([calculate_doc_vector(tokens) for tokens in train_data['Description']])\n",
    "X_test_vectors = np.array([calculate_doc_vector(tokens) for tokens in test_data['Description']])\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(train_data['Genre'])\n",
    "y_test_solution_encoded = label_encoder.transform(test_data_solution['Genre'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40bf7e91-6961-42e6-ae6a-c1d09db4c7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\susha\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_vectors, y_train_encoded)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf6b8d02-b8f2-49ca-800a-2a87808fd02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3626666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test_solution_encoded, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fbe225-30b5-4a1e-a326-b1670750abd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
