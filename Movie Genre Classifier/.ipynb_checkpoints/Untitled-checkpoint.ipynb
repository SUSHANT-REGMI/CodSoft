{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0df9e4-ea1f-4141-84ae-7ec51e330aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bc0e20-8976-4272-ad26-7b8c51882f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:/Users/susha/Downloads/archive (7)/Genre Classification Dataset/train_data.txt\", delimiter=':::', names = ['Sno', 'Name', 'Genre', 'Description'] ,engine='python')\n",
    "test_data = pd.read_csv(\"C:/Users/susha/Downloads/archive (7)/Genre Classification Dataset/test_data.txt\", delimiter = ':::', names = ['Sno', 'Name', 'Description'], engine='python')\n",
    "test_data_solution = pd.read_csv(\"C:/Users/susha/Downloads/archive (7)/Genre Classification Dataset/test_data_solution.txt\", delimiter=':::', names = ['Sno', 'Name', 'Genre', 'Description'] ,engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f9f292-a3a0-46e0-b6df-a4b1280835af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54195</th>\n",
       "      <td>54196</td>\n",
       "      <td>\"Tales of Light &amp; Dark\" (2013)</td>\n",
       "      <td>horror</td>\n",
       "      <td>Covering multiple genres, Tales of Light &amp; Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54196</th>\n",
       "      <td>54197</td>\n",
       "      <td>Der letzte Mohikaner (1965)</td>\n",
       "      <td>western</td>\n",
       "      <td>As Alice and Cora Munro attempt to find their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54197</th>\n",
       "      <td>54198</td>\n",
       "      <td>Oliver Twink (2007)</td>\n",
       "      <td>adult</td>\n",
       "      <td>A movie 169 years in the making. Oliver Twist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54198</th>\n",
       "      <td>54199</td>\n",
       "      <td>Slipstream (1973)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Popular, but mysterious rock D.J Mike Mallard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54199</th>\n",
       "      <td>54200</td>\n",
       "      <td>Curitiba Zero Grau (2010)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Curitiba is a city in movement, with rhythms ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sno                              Name      Genre  \\\n",
       "54195  54196   \"Tales of Light & Dark\" (2013)     horror    \n",
       "54196  54197      Der letzte Mohikaner (1965)    western    \n",
       "54197  54198              Oliver Twink (2007)      adult    \n",
       "54198  54199                Slipstream (1973)      drama    \n",
       "54199  54200        Curitiba Zero Grau (2010)      drama    \n",
       "\n",
       "                                             Description  \n",
       "54195   Covering multiple genres, Tales of Light & Da...  \n",
       "54196   As Alice and Cora Munro attempt to find their...  \n",
       "54197   A movie 169 years in the making. Oliver Twist...  \n",
       "54198   Popular, but mysterious rock D.J Mike Mallard...  \n",
       "54199   Curitiba is a city in movement, with rhythms ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()\n",
    "test_data.head()\n",
    "test_data_solution.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b222ada0-1e25-4649-bdd3-72bef19d2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54214\n",
      "         Sno                                    Name          Genre  \\\n",
      "0      54216                   Edgar's Lunch (1998)       thriller    \n",
      "1      54217               La guerra de pap√° (1977)         comedy    \n",
      "2      54218            Off the Beaten Track (2010)    documentary    \n",
      "3      54219                 Meu Amigo Hindu (2015)          drama    \n",
      "4      54220                      Er nu zhai (1955)          drama    \n",
      "...      ...                                     ...            ...   \n",
      "37695  91911                    Fully Loaded (2011)         comedy    \n",
      "37696  91912                    Tenebrae Lux (2014)         sci-fi    \n",
      "37697  91913                   Mexican Dance (1898)          short    \n",
      "37698  91914   Das Lied von den zwei Pferden (2009)    documentary    \n",
      "37699  91915                  Doin' It Again (2012)    documentary    \n",
      "\n",
      "                                             Description  \n",
      "0       L.R. Brane loves his life - his car, his apar...  \n",
      "1       Spain, March 1964: Quico is a very naughty ch...  \n",
      "2       One year in the life of Albin and his family ...  \n",
      "3       His father has died, he hasn't spoken with hi...  \n",
      "4       Before he was known internationally as a mart...  \n",
      "...                                                  ...  \n",
      "37695   On a rare evening out, two feisty single moms...  \n",
      "37696   A lone traveler with the ability to cross bet...  \n",
      "37697   \"Another well-known dancer with a national re...  \n",
      "37698   A promise, an old, destroyed horse head violi...  \n",
      "37699   50th Anniversary - 1st album of new material ...  \n",
      "\n",
      "[37700 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\susha\\AppData\\Local\\Temp\\ipykernel_15196\\1078671139.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_data = train_data.append(rows_to_append)\n"
     ]
    }
   ],
   "source": [
    "#code below adds the first 37700 data from test_data_solution into the train datasets and removes those respective data from itself and test_data\n",
    "\n",
    "last_sno = train_data['Sno'].max()\n",
    "print(last_sno)\n",
    "\n",
    "rows_to_append = test_data_solution.head(37700).copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "rows_to_append.loc[:, 'Sno'] += last_sno + 1  # Use .loc to modify the DataFrame safely\n",
    "\n",
    "print(rows_to_append)\n",
    "\n",
    "\n",
    "train_data = train_data.append(rows_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6e7c8e-5e1b-4a12-9567-f2f87e23d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(rows_to_append.index)\n",
    "test_data_solution = test_data_solution.drop(rows_to_append.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3596ac-1e92-4ce5-8ee0-9c8fc717808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_solution.reset_index(drop=True, inplace=True)\n",
    "test_data_solution.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ccd24a6-ca95-4c87-baac-7500ace3455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.reset_index(drop=True, inplace=True)\n",
    "test_data.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd2dfb5-327c-48c5-906d-3aebe90d6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737e5f47-319e-483a-984b-736ff178a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\susha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\susha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\susha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\susha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf805287-2907-403a-8cb0-f5c72728e515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\susha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc6d7987-24ca-4adc-b2f4-98300d39ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters, punctuation, and symbols\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply preprocessing to 'Description' column\n",
    "train_data['Description'] = train_data['Description'].apply(preprocess_text)\n",
    "test_data['Description'] = test_data['Description'].apply(preprocess_text)\n",
    "test_data_solution['Description'] = test_data_solution['Description'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11fa4ccd-223e-4095-bb59-e81b7141e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data['Description']\n",
    "y_train = train_data['Genre']\n",
    "X_test = test_data['Description']\n",
    "y_test_solution = test_data_solution['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be3990f-e7bf-44b0-8e0d-751adb3cb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to calculate document vectors\n",
    "def calculate_doc_vector(tokens):\n",
    "    vectors = [word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "# Calculate document vectors for train and test data\n",
    "X_train_vectors = np.array([calculate_doc_vector(tokens) for tokens in X_train])\n",
    "X_test_vectors = np.array([calculate_doc_vector(tokens) for tokens in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c9c69-2b8a-4c1c-a619-f5a4b8884261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Perform the same encoding for test labels if needed\n",
    "y_test_encoded = label_encoder.transform(y_test_solution)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train_vectors.shape[1],)),\n",
    "    Dropout(0.7),  # Add dropout layer to prevent overfitting\n",
    "    Dense(256, activation='relu'),\n",
    "    # Dropout(0.7),\n",
    "    Dense(128, activation='relu'),\n",
    "    # Dropout(0.7),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "\n",
    "    # Dropout(0.7),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')  # Assuming y_train is one-hot encoded\n",
    "])\n",
    "optimizer = Adam(learning_rate=0.003)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "history = model.fit(X_train_vectors, y_train_encoded, epochs=20, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582975a0-543b-4248-9abf-12ee9d89f087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465734b4-2dd3-43a5-a096-78c089180bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
